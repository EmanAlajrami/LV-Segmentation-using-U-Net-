{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet_kfold_cross_val.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmanAlajrami/LV-Segmentation-using-U-Net-/blob/main/Unet_kfold_cross_val.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jw9KdyhGXTm"
      },
      "source": [
        "\"\"\" \n",
        "The U-Net model is from the reposotory \n",
        "https://github.com/intsav \n",
        "\n",
        "@ auther Eman Alajrami\n",
        "\n",
        "My expiremnt with U-Net segmentation model using KFold cross validation\n",
        "\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQX7R4bhZy5h"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.python.keras import losses\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ***********/Trying to use K_Fold cross validation /*******\n",
        "\n",
        "EPOCHS = 50\n",
        "OUTPUT_CHANNELS = 1 # no of classes\n",
        "input_shape_image = [512,512,1] \n",
        "BATCH_SIZE = 8\n",
        "BUFFER_SIZE = 1000\n",
        "do_training = True"
      ],
      "metadata": {
        "id": "7Md1eT_85Gg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW7UJxgdQE0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a5dde3-8e5e-43de-b7e2-38ff6cac9532"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "%cd /content/gdrive/My Drive/Colab Notebooks\n",
        "print('os.path = ', os.path)\n",
        "!#ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[Errno 2] No such file or directory: '/content/gdrive/My Drive/Colab Notebooks'\n",
            "/content\n",
            "os.path =  <module 'posixpath' from '/usr/lib/python3.7/posixpath.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD60EbcAQqov"
      },
      "source": [
        "def normalize(input_image, input_mask):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  #input_mask -= 1\n",
        "  return input_image, input_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NPlCnBXQwb1"
      },
      "source": [
        "def load_image_train(datapoint):\n",
        "  SIZE = 512  #1024\n",
        "  input_image = tf.image.resize(datapoint['image'], (SIZE, SIZE))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (SIZE, SIZE))\n",
        "\n",
        "  # if tf.random.uniform(()) > 0.5:\n",
        "  #   input_image = tf.image.flip_left_right(input_image)\n",
        "  #   input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf0S67hJRp3D"
      },
      "source": [
        "def load_image_test(datapoint):\n",
        "  SIZE = 512 #1024\n",
        "  input_image = tf.image.resize(datapoint['image'], (SIZE, SIZE))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (SIZE, SIZE))\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8odBMyD9zsd6"
      },
      "source": [
        "def load_image_val(datapoint):\n",
        "  SIZE = 512 #1024\n",
        "  input_image = tf.image.resize(datapoint['image'], (SIZE, SIZE))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (SIZE, SIZE))\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N2RPAAW9q4W"
      },
      "source": [
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAOe93FRMk3w"
      },
      "source": [
        "## Define the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kSNBNuGsy0e"
      },
      "source": [
        "def conv_block(input_tensor, num_filters):\n",
        "  encoder = tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
        "  encoder = tf.keras.layers.BatchNormalization()(encoder)\n",
        "  encoder = tf.keras.layers.Activation('relu')(encoder)\n",
        "  encoder = tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
        "  encoder = tf.keras.layers.BatchNormalization()(encoder)\n",
        "  encoder = tf.keras.layers.Activation('relu')(encoder)\n",
        "  return encoder\n",
        "\n",
        "def encoder_block(input_tensor, num_filters):\n",
        "  encoder = conv_block(input_tensor, num_filters)\n",
        "  encoder_pool = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
        "  \n",
        "  return encoder_pool, encoder\n",
        "\n",
        "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
        "  decoder = tf.keras.layers.Conv2DTranspose(num_filters, (3, 3), strides=(2, 2), padding='same')(input_tensor)\n",
        "  decoder = tf.keras.layers.concatenate([concat_tensor, decoder], axis=-1)\n",
        "  decoder = tf.keras.layers.BatchNormalization()(decoder)\n",
        "  decoder = tf.keras.layers.Activation('relu')(decoder)\n",
        "  decoder = tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "  decoder = tf.keras.layers.BatchNormalization()(decoder)\n",
        "  decoder = tf.keras.layers.Activation('relu')(decoder)\n",
        "  decoder = tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "  decoder = tf.keras.layers.BatchNormalization()(decoder)\n",
        "  decoder = tf.keras.layers.Activation('relu')(decoder)\n",
        "  return decoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzj_HPW30lUw"
      },
      "source": [
        "##Defining custom metrics and loss functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC7izudT7PYZ"
      },
      "source": [
        "def dice_coeff(y_true, y_pred, loss_type='sorensen', smooth=1.):\n",
        "    \"\"\"Soft dice (Sørensen or Jaccard) coefficient for comparing the similarity\n",
        "    of two batch of data, usually be used for binary image segmentation\n",
        "    i.e. labels are binary. The coefficient between 0 to 1, 1 means totally match.\n",
        "    Parameters\n",
        "    -----------\n",
        "    y_true : Tensor\n",
        "        A distribution with shape: [batch_size, ....], (any dimensions).\n",
        "    y_pred : Tensor\n",
        "        The target distribution, format the same with `output`.\n",
        "    loss_type : str\n",
        "        ``jaccard`` or ``sorensen``, default is ``jaccard``.\n",
        "    smooth : float\n",
        "        This small value will be added to the numerator and denominator.\n",
        "            - If both output and target are empty, it makes sure dice is 1.\n",
        "            - If either output or target are empty (all pixels are background),\n",
        "            dice = ```smooth/(small_value + smooth)``,\n",
        "            then if smooth is very small, dice close to 0 (even the image values lower than the threshold),\n",
        "            so in this case, higher smooth can have a higher dice.\n",
        "    References\n",
        "    -----------\n",
        "    - `Wiki-Dice <https://en.wikipedia.org/wiki/Sørensen–Dice_coefficient>`__\n",
        "    \"\"\"\n",
        "    \n",
        "    # https://lars76.github.io/neural-networks/object-detection/losses-for-segmentation/\n",
        "    #numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n",
        "    #denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n",
        "    #score = (numerator + 1) / (denominator + 1)\n",
        "   \n",
        "    # Flatten\n",
        "    y_true_f = tf.reshape(y_true, [-1])\n",
        "    y_pred_f = tf.reshape(y_pred, [-1])\n",
        "    #y_true_f = tf.layers.flatten(y_true)\n",
        "    #y_pred_f = tf.layers.flatten(y_pred)\n",
        "\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    \n",
        "    if loss_type == 'jaccard':\n",
        "        union = tf.reduce_sum(tf.square(y_pred_f)) + tf.reduce_sum(tf.square(y_true_f))\n",
        "\n",
        "    elif loss_type == 'sorensen':\n",
        "        union = tf.reduce_sum(y_pred_f) + tf.reduce_sum(y_true_f)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unknown `loss_type`: %s\" % loss_type)\n",
        "\n",
        "    score = (2. * intersection + smooth) / (union + smooth)\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFaBbMnWK17w"
      },
      "source": [
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coeff(y_true, y_pred)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNOq9v5n02CR"
      },
      "source": [
        "def bce_dice_loss(y_true, y_pred):\n",
        "    #y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    #y_pred = tf.dtypes.cast(y_pred, tf.int64)\n",
        "    loss = losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage.morphology import distance_transform_edt, binary_erosion, generate_binary_structure\n",
        "from scipy.ndimage import _ni_support\n",
        "\n",
        "def __surface_distances(result, reference, voxelspacing=None, connectivity=1):\n",
        "    \"\"\"\n",
        "    The distances between the surface voxel of binary objects in result and their\n",
        "    nearest partner surface voxel of a binary object in reference.\n",
        "    \"\"\"\n",
        "    result = np.array(result, dtype=np.bool)\n",
        "    result = np.atleast_1d(result)\n",
        "    reference = np.array(reference, dtype=np.bool)\n",
        "    reference = np.atleast_1d(reference)\n",
        "    \n",
        "    #result = np.atleast_1d(result.astype(np.bool))\n",
        "    #reference = np.atleast_1d(reference.astype(np.bool))\n",
        "    \n",
        "    if voxelspacing is not None:\n",
        "        voxelspacing = _ni_support._normalize_sequence(voxelspacing, result.ndim)\n",
        "        voxelspacing = np.asarray(voxelspacing, dtype=np.float64)\n",
        "        if not voxelspacing.flags.contiguous:\n",
        "            voxelspacing = voxelspacing.copy()\n",
        "            \n",
        "    # binary structure\n",
        "    footprint = generate_binary_structure(result.ndim, connectivity)\n",
        "    \n",
        "    # test for emptiness\n",
        "    if 0 == np.count_nonzero(result): \n",
        "        raise RuntimeError('The first supplied array does not contain any binary object.')\n",
        "    if 0 == np.count_nonzero(reference): \n",
        "        raise RuntimeError('The second supplied array does not contain any binary object.')    \n",
        "            \n",
        "    # extract only 1-pixel border line of objects\n",
        "    result_border = result ^ binary_erosion(result, structure=footprint, iterations=1)\n",
        "    reference_border = reference ^ binary_erosion(reference, structure=footprint, iterations=1)\n",
        "    \n",
        "    # compute average surface distance        \n",
        "    # Note: scipys distance transform is calculated only inside the borders of the\n",
        "    #       foreground objects, therefore the input has to be reversed\n",
        "    dt = distance_transform_edt(~reference_border, sampling=voxelspacing)\n",
        "    sds = dt[result_border]\n",
        "    \n",
        "    return sds"
      ],
      "metadata": {
        "id": "CEpvECb16PUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Hausdorff_Distance(reference, result, voxelspacing=None, connectivity=1):\n",
        "    \"\"\"\n",
        "    Hausdorff Distance.\n",
        "    \n",
        "    Computes the (symmetric) Hausdorff Distance (HD) between the binary objects in two\n",
        "    images. It is defined as the maximum surface distance between the objects.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    result : array_like\n",
        "        Input data containing objects. Can be any type but will be converted\n",
        "        into binary: background where 0, object everywhere else.\n",
        "    reference : array_like\n",
        "        Input data containing objects. Can be any type but will be converted\n",
        "        into binary: background where 0, object everywhere else.\n",
        "    voxelspacing : float or sequence of floats, optional\n",
        "        The voxelspacing in a distance unit i.e. spacing of elements\n",
        "        along each dimension. If a sequence, must be of length equal to\n",
        "        the input rank; if a single number, this is used for all axes. If\n",
        "        not specified, a grid spacing of unity is implied.\n",
        "    connectivity : int\n",
        "        The neighbourhood/connectivity considered when determining the surface\n",
        "        of the binary objects. This value is passed to\n",
        "        `scipy.ndimage.morphology.generate_binary_structure` and should usually be :math:`> 1`.\n",
        "        Note that the connectivity influences the result in the case of the Hausdorff distance.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    hd : float\n",
        "        The symmetric Hausdorff Distance between the object(s) in ```result``` and the\n",
        "        object(s) in ```reference```. The distance unit is the same as for the spacing of \n",
        "        elements along each dimension, which is usually given in mm.\n",
        "        \n",
        "    See also\n",
        "    --------\n",
        "    :func:`assd`\n",
        "    :func:`asd`\n",
        "    \n",
        "    Notes\n",
        "    -----\n",
        "    This is a real metric. The binary images can therefore be supplied in any order.\n",
        "    \"\"\"\n",
        "    hd1 = __surface_distances(result, reference, voxelspacing, connectivity).max()\n",
        "    hd2 = __surface_distances(reference, result, voxelspacing, connectivity).max()\n",
        "    hd = max(hd1, hd2)\n",
        "    return hd"
      ],
      "metadata": {
        "id": "IJ_fOGVG6ZFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Dice_Coefficient(reference, result):\n",
        "    \"\"\"\n",
        "    Computes the Dice coefficient (also known as Sorensen index) between the binary objects in two images.\n",
        "\n",
        "    result : Input data containing objects. Can be any type but will be converted\n",
        "        into binary: background where 0, object everywhere else.\n",
        "    reference : Input data containing objects. Can be any type but will be converted\n",
        "        into binary: background where 0, object everywhere else.\n",
        "    \"\"\"\n",
        "    result = np.array(result, dtype=np.bool)\n",
        "    result = np.atleast_1d(result)\n",
        "    result = tf.reshape(result, [-1])\n",
        "\n",
        "    reference = np.array(reference, dtype=np.bool)\n",
        "    reference = np.atleast_1d(reference)\n",
        "    reference = tf.reshape(reference, [-1])\n",
        "    \n",
        "    intersection = np.count_nonzero(result & reference)\n",
        "    \n",
        "    size_i1 = np.count_nonzero(result)\n",
        "    size_i2 = np.count_nonzero(reference)\n",
        "    \n",
        "    try:\n",
        "        dc = 2. * intersection / float(size_i1 + size_i2)\n",
        "    except ZeroDivisionError:\n",
        "        dc = 0.0\n",
        "    \n",
        "    return dc"
      ],
      "metadata": {
        "id": "aWa8F0gI6sZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwvIKLZPtxV_"
      },
      "source": [
        "def create_mask(pred_mask):\n",
        " \n",
        "  pred_mask = tf.greater(pred_mask, 0.5)\n",
        "  pred_mask = tf.dtypes.cast(pred_mask, tf.float32)\n",
        "  pred_mask = pred_mask[0]\n",
        "  return pred_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLNsrynNtx4d"
      },
      "source": [
        "def show_predictions(dataset=None, num=1):\n",
        "  if dataset:\n",
        "    for image, mask in dataset.take(num):\n",
        "      pred_mask = model.predict(image)\n",
        "      display([image[0], mask[0], create_mask(pred_mask)])\n",
        "  else:\n",
        "    display([sample_image, sample_mask, create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57NiiNTp3FWG"
      },
      "source": [
        "## Callbacks \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKUAL6ni3JmS"
      },
      "source": [
        "save_model_path = '/content/drive/MyDrive/Unet/weights-binary_lvnew.hdf5'\n",
        "#cp = tf.keras.callbacks.ModelCheckpoint(filepath=save_model_path, monitor='val_dice_loss', mode='auto', save_best_only=True)\n",
        "cp = tf.keras.callbacks.ModelCheckpoint(filepath=save_model_path, monitor='val_loss', mode='auto', save_best_only=True)\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta=0,patience=10,verbose =1,restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHrHsqijdmL6"
      },
      "source": [
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    clear_output(wait=True)\n",
        "    show_predictions()\n",
        "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKUYCwr86xfc"
      },
      "source": [
        "x_train_path=\"/content/drive/MyDrive/MyDataset/dataset/images/training\"\n",
        "y_train_path=\"/content/drive/MyDrive/MyDataset/dataset/annotations_binary/training\"\n",
        "x_test_path=\"/content/drive/MyDrive/MyDataset/dataset/images/testing/\"\n",
        "y_test_path=\"/content/drive/MyDrive/MyDataset/dataset/annotations_binary/testing/\"\n",
        "X = []\n",
        "Y = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDwpZkVa8Thj"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "for filename in os.listdir(x_train_path):\n",
        "  path=os.path.join(x_train_path, filename)\n",
        "  im = cv2.imread(path)\n",
        "  X.append(im)\n",
        "for filename in os.listdir(x_test_path):\n",
        "  path=os.path.join(x_test_path, filename)\n",
        "  im = cv2.imread(path)\n",
        "  X.append(im)\n",
        "for filename in os.listdir(y_train_path):\n",
        "  path=os.path.join(y_train_path, filename)\n",
        "  im = cv2.imread(path)\n",
        "  Y.append(im)\n",
        "for filename in os.listdir(y_test_path):\n",
        "  path=os.path.join(y_test_path, filename)\n",
        "  im = cv2.imread(path)\n",
        "  Y.append(im)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOqgDsW-_5Zx",
        "outputId": "6ee828c0-c33b-4416-9ca1-9670c24c4a6f"
      },
      "source": [
        "# Convert to Numpy Array\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "# Normalize data\n",
        "X  = X/255\n",
        "Y  = Y/255\n",
        "\n",
        "# Define total folds\n",
        "num_folds = 5\n",
        "\n",
        "# Define per-fold score containers\n",
        "\n",
        "loss_per_fold = []\n",
        "acc_per_fold  = []\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYxTzI0F0jjL"
      },
      "source": [
        "# Using K-Fold Cross validation \n",
        "\n",
        "# Define per-fold score containers\n",
        "# Merge inputs and targets\n",
        "#train_dataset = np.concatenate((train_dataset, val_dataset), axis=0)\n",
        "#inputs = np.concatenate((input_train, input_test), axis=0)\n",
        "#targets = np.concatenate((target_train, target_test), axis=0)\n",
        "\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "#kfold = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "n_split =5\n",
        "fold_no = 1\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "for train, test in kfold.split(X, Y):\n",
        "  x_train = X[train]\n",
        "  y_train = Y[train]\n",
        "  x_test  = X[test]\n",
        "  y_test  = Y[test]\n",
        "  \n",
        "\n",
        "  # build the model \n",
        "  inputs = tf.keras.layers.Input(shape=input_shape_image)\n",
        "\n",
        "  encoder0_pool, encoder0 = encoder_block(inputs, 32)\n",
        "  encoder1_pool, encoder1 = encoder_block(encoder0_pool, 64)\n",
        "  encoder2_pool, encoder2 = encoder_block(encoder1_pool, 128)\n",
        "  encoder3_pool, encoder3 = encoder_block(encoder2_pool, 256)\n",
        "  encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512)\n",
        "\n",
        "  center = conv_block(encoder4_pool, 1024)\n",
        "\n",
        "  decoder4 = decoder_block(center, encoder4, 512)\n",
        "  decoder3 = decoder_block(decoder4, encoder3, 256)\n",
        "  decoder2 = decoder_block(decoder3, encoder2, 128)\n",
        "  decoder1 = decoder_block(decoder2, encoder1, 64)\n",
        "  decoder0 = decoder_block(decoder1, encoder0, 32)\n",
        "\n",
        "  outputs = tf.keras.layers.Conv2D(OUTPUT_CHANNELS, (1, 1), activation='sigmoid')(decoder0)\n",
        "\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "#Compile \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=TRAIN_SEG_LEARNING_RATE), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "## Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model-  Train  \n",
        "  if do_training:\n",
        "     model_history =   model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[DisplayCallback(),cp,early_stop ])\n",
        "   # Generate generalization metrics\n",
        "  scores = model.evaluate(x_test, verbose=0)\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsqDFW-f7sl_"
      },
      "source": [
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXBIDbLU0p57"
      },
      "source": [
        "# Visualize training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_mu0SAbt40Q"
      },
      "source": [
        "if do_training:\n",
        "  loss     = model_history.history['loss']\n",
        "  val_loss = model_history.history['val_loss']\n",
        "\n",
        "  epochs = range(EPOCHS)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss Value')\n",
        "  plt.ylim([0, 1])\n",
        "  plt.legend(loc='upper right')\n",
        "\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8Pp_N6tzvQ8"
      },
      "source": [
        "# Visualize actual performance \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoKHUcBDzzwY"
      },
      "source": [
        "\n",
        "if not do_training:\n",
        "  model.load_weights(save_model_path)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unP3cnxo_N72"
      },
      "source": [
        "## Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikrzoG24qwf5"
      },
      "source": [
        "show_predictions(test_dataset, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYntqCGBmJED"
      },
      "source": [
        "for image, mask in test_dataset.take(num_test_examples):\n",
        "  pred_mask = model.predict(image)\n",
        "\n",
        "  print('Hausdorff_Distance = ', Hausdorff_Distance(mask[0], create_mask(pred_mask)))\n",
        "  DC = Dice_Coefficient(mask[0], create_mask(pred_mask))\n",
        "  print(DC/(2-DC))\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPDWgLltWpZN"
      },
      "source": [
        "\n",
        "model_history.history\n",
        "print(np.mean(model_history.history['accuracy']))\n",
        "print(np.mean(model_history.history['val_accuracy']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AZv6f3dYQbl"
      },
      "source": [
        "DC_list= []\n",
        "HD_list =[]\n",
        "for image, mask in test_dataset.take(num_test_examples):\n",
        "  pred_mask = model.predict(image)\n",
        "  DC = Dice_Coefficient(mask[0], create_mask(pred_mask))\n",
        "  DC_list.append ((DC/(2-DC)))\n",
        "  HD = Hausdorff_Distance(mask[0], create_mask(pred_mask))\n",
        "  HD_list.append(HD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVfy621BaEbe"
      },
      "source": [
        "# print the average Dice and average HD\n",
        "print('DC= ',np.mean(DC_list))\n",
        "print('HD =', np.mean(HD_list))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}